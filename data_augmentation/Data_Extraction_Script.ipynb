{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e1efe4d-ec0f-42c9-9070-cf83d9d8dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7465cd75-8d5d-40cc-bebf-0577a5a5aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "from shutil import copyfile\n",
    "\n",
    "import io, tokenize, re, os\n",
    "from DatasetUtils import py_cleaner, c_cleaner, add_to_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e3e0f7-1663-4474-bc44-f0a7b5675f1b",
   "metadata": {},
   "source": [
    "### Data Directories\n",
    "1. `csv_labels` contains all the CSV files that needs to contain the data labels in our dataset.\n",
    "2. `old_data` - Data labeled prior to the second semester\n",
    "3. `new_data` - Data labeled after the second semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d4d610d-57ce-49b9-a355-4d529ef5aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_labels = './csv_labels'\n",
    "old_data   = './old_data'\n",
    "new_data   = './new_data'\n",
    "destination = './destination'\n",
    "\n",
    "columns = ['quicksort', 'mergesort', 'selectionsort', 'insertionsort', 'bubblesort', 'linearsearch', 'binarysearch', 'linkedlist', 'hashmap']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a729b1a1-74cb-40db-83b7-47fd21664be4",
   "metadata": {},
   "source": [
    "### CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ce1ca7a-2af2-4e64-96da-1ed277d7f059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hash-Map'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = lambda key : (filter(lambda fname: key in fname, os.listdir('csv_labels')));\n",
    "folder_name = lambda fname : fname[4:-4]\n",
    "folder_name('old-Hash-Map.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37d43c5f-c869-48be-bfd8-9e4bf28c88d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_csvs = csv_files('new')\n",
    "\n",
    "file_counter = 0\n",
    "file_not_founds = 0\n",
    "indentation_errors = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06c2bcb3-76a9-4e6c-a14d-1ad2b985719a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1328\n"
     ]
    }
   ],
   "source": [
    "old_csvs = csv_files('old')\n",
    "\n",
    "\n",
    "old_csv_data = []\n",
    "\n",
    "for csv_filename in old_csvs:\n",
    "    folder = f'{old_data}/{folder_name(csv_filename)}'\n",
    "    \n",
    "    df = pd.read_csv(f'{csv_labels}/{csv_filename}')\n",
    "    \n",
    "    for idx, row in df.iterrows():        \n",
    "        labels = row[columns].to_dict()\n",
    "        filename = row['Filename']\n",
    "        labels['Filename'] = file_counter\n",
    "        \n",
    "        fname_splitted = filename.split('.')\n",
    "        \n",
    "        if (len(fname_splitted)) >= 2:\n",
    "            extension = fname_splitted[len(fname_splitted) - 1]\n",
    "            fname1 = fname_splitted[0:len(fname_splitted) - 1]\n",
    "        else:\n",
    "            fname1 = fname_splitted\n",
    "            extension = 'py'\n",
    "        \n",
    "        # Now, we get the file with the filename\n",
    "        try:\n",
    "            with open(f'{folder}/{filename}', encoding='utf8', errors='ignore') as file:\n",
    "                if extension in ['java', 'js']:\n",
    "                    q = c_cleaner(file.read())\n",
    "                else:\n",
    "                    q = py_cleaner(file.read())\n",
    "\n",
    "                # Copy the file\n",
    "                with open(f'{destination}/{file_counter}', 'w', encoding='utf8') as newfile:\n",
    "                    newfile.write(q)\n",
    "            old_csv_data.append(labels)\n",
    "            file_counter += 1\n",
    "        except FileNotFoundError:\n",
    "            file_not_founds += 1\n",
    "        except IndentationError:\n",
    "            indentation_errors += 1\n",
    "            \n",
    "        \n",
    "        \n",
    "        #print(old_csv_data)\n",
    "print(len(old_csv_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3da0c67b-806a-4910-98a8-fd32df0484dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485\n"
     ]
    }
   ],
   "source": [
    "new_csvs = csv_files('new')\n",
    "\n",
    "new_csv_data = []\n",
    "\n",
    "for csv_filename in new_csvs:\n",
    "    folder = f'{new_data}/{folder_name(csv_filename)}'\n",
    "    \n",
    "    df = pd.read_csv(f'{csv_labels}/{csv_filename}')\n",
    "    \n",
    "    for idx, row in df.iterrows():        \n",
    "        labels = row[columns].to_dict()\n",
    "        filename = row['Filename']\n",
    "        labels['Filename'] = file_counter\n",
    "        \n",
    "        fname_splitted = filename.split('.')\n",
    "        \n",
    "        if (len(fname_splitted)) >= 2:\n",
    "            extension = fname_splitted[len(fname_splitted) - 1]\n",
    "            fname1 = fname_splitted[0:len(fname_splitted) - 1]\n",
    "        else:\n",
    "            fname1 = fname_splitted\n",
    "            extension = 'py'\n",
    "        \n",
    "        # Now, we get the file with the filename\n",
    "        try:\n",
    "            with open(f'{folder}/{filename}', encoding='utf8', errors='ignore') as file:\n",
    "                if extension in ['java', 'js']:\n",
    "                    q = c_cleaner(file.read())\n",
    "                else:\n",
    "                    q = py_cleaner(file.read())\n",
    "\n",
    "                # Copy the file\n",
    "                with open(f'{destination}/{file_counter}', 'w', encoding='utf8') as newfile:\n",
    "                    newfile.write(q)\n",
    "            \n",
    "            new_csv_data.append(labels)\n",
    "            file_counter += 1\n",
    "        except FileNotFoundError:\n",
    "            file_not_founds += 1\n",
    "        except IndentationError:\n",
    "            indentation_errors += 1\n",
    "        \n",
    "        \n",
    "        #print(old_csv_data)\n",
    "print(len(new_csv_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8651e8f-6a34-4710-a86f-fbcff2a84ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16676\n"
     ]
    }
   ],
   "source": [
    "augmented_csvs = ['AUGMENTATION/augmented.csv']\n",
    "\n",
    "augmented_csv_data = []\n",
    "\n",
    "for csv_filename in augmented_csvs:\n",
    "    folder = f'AUGMENTATION/augmented'\n",
    "    \n",
    "    df = pd.read_csv(f'{csv_filename}')\n",
    "    \n",
    "    for idx, row in df.iterrows():        \n",
    "        labels = row[columns].to_dict()\n",
    "        filename = row['Filename']\n",
    "        labels['Filename'] = file_counter\n",
    "        \n",
    "        fname_splitted = filename.split('.')\n",
    "        \n",
    "        if (len(fname_splitted)) >= 2:\n",
    "            extension = fname_splitted[len(fname_splitted) - 1]\n",
    "            fname1 = fname_splitted[0:len(fname_splitted) - 1]\n",
    "        else:\n",
    "            fname1 = fname_splitted\n",
    "            extension = 'py'\n",
    "        \n",
    "        # Now, we get the file with the filename\n",
    "        try:\n",
    "            with open(f'{folder}/{filename}', encoding='utf8', errors='ignore') as file:\n",
    "                if extension in ['java', 'js']:\n",
    "                    q = c_cleaner(file.read())\n",
    "                else:\n",
    "                    q = py_cleaner(file.read())\n",
    "\n",
    "                # Copy the file\n",
    "                with open(f'{destination}/{file_counter}', 'w', encoding='utf8') as newfile:\n",
    "                    newfile.write(q)\n",
    "            \n",
    "            augmented_csv_data.append(labels)\n",
    "            file_counter += 1\n",
    "        except FileNotFoundError:\n",
    "            file_not_founds += 1\n",
    "        except IndentationError:\n",
    "            indentation_errors += 1\n",
    "        \n",
    "        \n",
    "        #print(old_csv_data)\n",
    "print(len(augmented_csv_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2957660-efb2-4f32-a57b-752984ce7caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13032\n"
     ]
    }
   ],
   "source": [
    "intercalated_csvs = ['Intercalated.csv']\n",
    "\n",
    "intercalated_csv_data = []\n",
    "\n",
    "for csv_filename in intercalated_csvs:\n",
    "    folder = f'intercalate_augment'\n",
    "    \n",
    "    df = pd.read_csv(f'{csv_filename}')\n",
    "    \n",
    "    for idx, row in df.iterrows():        \n",
    "        labels = row[columns].to_dict()\n",
    "        filename = row['Filename']\n",
    "        labels['Filename'] = file_counter\n",
    "        \n",
    "        fname_splitted = filename.split('.')\n",
    "        \n",
    "        if (len(fname_splitted)) >= 2:\n",
    "            extension = fname_splitted[len(fname_splitted) - 1]\n",
    "            fname1 = fname_splitted[0:len(fname_splitted) - 1]\n",
    "        else:\n",
    "            fname1 = fname_splitted\n",
    "            extension = 'py'\n",
    "        \n",
    "        # Now, we get the file with the filename\n",
    "        try:\n",
    "            with open(f'{folder}/{filename}', encoding='utf8', errors='ignore') as file:\n",
    "                if extension in ['java', 'js']:\n",
    "                    q = c_cleaner(file.read())\n",
    "                else:\n",
    "                    q = py_cleaner(file.read())\n",
    "\n",
    "                # Copy the file\n",
    "                with open(f'{destination}/{file_counter}', 'w', encoding='utf8') as newfile:\n",
    "                    newfile.write(q)\n",
    "            \n",
    "            intercalated_csv_data.append(labels)\n",
    "            file_counter += 1\n",
    "        except FileNotFoundError:\n",
    "            file_not_founds += 1\n",
    "        except IndentationError:\n",
    "            indentation_errors += 1\n",
    "        \n",
    "        \n",
    "        #print(old_csv_data)\n",
    "print(len(intercalated_csv_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acb3c41e-edc6-4f14-91f2-9544f6bf3059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31521"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dictionaries = old_csv_data + new_csv_data + augmented_csv_data + intercalated_csv_data\n",
    "len(final_dictionaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "539fa7c1-e69a-4b9e-b8df-e5a6db7568de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quicksort</th>\n",
       "      <th>mergesort</th>\n",
       "      <th>selectionsort</th>\n",
       "      <th>insertionsort</th>\n",
       "      <th>bubblesort</th>\n",
       "      <th>linearsearch</th>\n",
       "      <th>binarysearch</th>\n",
       "      <th>linkedlist</th>\n",
       "      <th>hashmap</th>\n",
       "      <th>Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31516</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31517</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31518</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31519</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31520</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31521 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       quicksort  mergesort  selectionsort  insertionsort  bubblesort  \\\n",
       "0              0          0              0              0           0   \n",
       "1              0          0              0              0           0   \n",
       "2              0          0              0              0           0   \n",
       "3              0          0              0              0           0   \n",
       "4              0          0              0              0           0   \n",
       "...          ...        ...            ...            ...         ...   \n",
       "31516          0          0              1              0           1   \n",
       "31517          1          0              0              1           0   \n",
       "31518          1          0              0              1           0   \n",
       "31519          0          0              1              0           0   \n",
       "31520          0          0              1              0           0   \n",
       "\n",
       "       linearsearch  binarysearch  linkedlist  hashmap  Filename  \n",
       "0                 0             0           0        0         0  \n",
       "1                 0             0           0        0         1  \n",
       "2                 1             0           0        1         2  \n",
       "3                 0             0           0        0         3  \n",
       "4                 0             0           0        0         4  \n",
       "...             ...           ...         ...      ...       ...  \n",
       "31516             0             0           0        0     31516  \n",
       "31517             0             0           0        0     31517  \n",
       "31518             0             0           0        0     31518  \n",
       "31519             0             0           0        0     31519  \n",
       "31520             0             0           0        0     31520  \n",
       "\n",
       "[31521 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_file = pd.DataFrame(final_dictionaries)\n",
    "label_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e41ae72-a6c0-4e98-bad5-00b321e76039",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file.to_csv('final_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ce788-39ff-495b-903c-6a8e4a4bd194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
