{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f46572-a238-411e-9360-bb4c4fe7a09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6656eb12-0769-4adc-97f0-21c0449d369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "from shutil import copyfile\n",
    "\n",
    "import io, tokenize, re, os\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from random import randint\n",
    "\n",
    "from augment import find_all_files, flatten, intercalate_files\n",
    "from DatasetUtils import py_cleaner, c_cleaner, add_to_list\n",
    "\n",
    "working_dir = 'intercalate_working'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1887968f-e4fe-4f6f-b437-404e6c713c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1997"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exts = ['java', 'py', 'js']\n",
    "\n",
    "allowed_files = flatten([find_all_files(['old_data', 'new_data'], ext, 90) for ext in exts])\n",
    "len(allowed_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dece7ee-6871-4877-82a2-061f6722dbc9",
   "metadata": {},
   "source": [
    "Out of all the files that was gotten, let's check which ones have labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c51e8b9b-3f8e-4c51-af27-dde71aaea1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['quicksort', 'mergesort', 'selectionsort', 'insertionsort', \n",
    "        'bubblesort', 'linearsearch', 'binarysearch', 'linkedlist', 'hashmap']\n",
    "\n",
    "final_file_list = []\n",
    "\n",
    "for f in allowed_files:\n",
    "    which_folder, label_folder, filename = f.split('/')\n",
    "    #print(f)\n",
    "    prefix = 'old' if which_folder == 'old_data' else 'new'\n",
    "    \n",
    "    df = pd.read_csv(f'csv_labels/{prefix}-{label_folder}.csv')\n",
    "    loc = df.loc[df['Filename'] == filename]\n",
    "    \n",
    "    # If no such row exists, then let go of the file.\n",
    "    if len(loc) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        haslabels = loc[cols].sum(axis=1).values.tolist()[0]\n",
    "        # Only consider those with labels \n",
    "        if haslabels:\n",
    "            # Then we add its column along with the filename\n",
    "            row = [f'{prefix}_{label_folder}_{filename}', *flatten(loc[cols].values.tolist())]\n",
    "            # Copy the file to our working directory.\n",
    "            copyfile(f, f'{working_dir}/{prefix}_{label_folder}_{filename}')\n",
    "            #print(row)\n",
    "            final_file_list.append(row)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5c2d7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1272"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf43e4b5-5a39-4d88-9a13-7fd5adbae858",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = pd.DataFrame(final_file_list, columns=['Filename', *cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f32450f3-5c07-4220-8087-55756dd9613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ext_files = lambda ext: list(filter(lambda x: f'.{ext}' in x, working_df['Filename']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3e3b4e-707b-4f1b-a8b2-47962893d6a1",
   "metadata": {},
   "source": [
    "Augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae59ff71-18bd-4b29-8013-ac8fb5cb8955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished! Total augmented files: 19143\n"
     ]
    }
   ],
   "source": [
    "final_df_list = []\n",
    "\n",
    "for ext in exts:\n",
    "    files = get_ext_files(ext)\n",
    "    combs = combinations(files, 2)\n",
    "    \n",
    "    # Let's have a 5% chance of the file being intercalated.\n",
    "    for comb in combs:\n",
    "        intercalate = randint(0, 100) < 4\n",
    "        if intercalate:\n",
    "            \n",
    "            rows = intercalate_files(working_df, ext, *list(map(lambda x: f'{working_dir}/{x}', list(comb))))\n",
    "            if len(rows) > 0:\n",
    "                for row in rows:\n",
    "                    final_df_list.append(row)\n",
    "print(f'Finished! Total augmented files: {len(final_df_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee184373-c296-49d6-a287-045a12f92373",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(final_df_list, columns=['Filename', *cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79f98adc-0c43-4e26-b7ca-b5258df6bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('Intercalated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b207b30-3f3e-4a87-9016-242715b8becc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
