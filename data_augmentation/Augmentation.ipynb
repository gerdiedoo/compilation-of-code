{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b6edcc1e-661c-4532-8bd3-78894fe69353",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89b8dfbb-0caf-470c-8941-abbf207459d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "from shutil import copyfile\n",
    "from copy import deepcopy\n",
    "\n",
    "import io, tokenize, re, os\n",
    "\n",
    "from random import randint\n",
    "\n",
    "from augment import generate_new_code, generate_keywords\n",
    "\n",
    "from DatasetUtils import py_cleaner, c_cleaner, add_to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9b2b6e0-f8d5-42bc-9b0e-0890298160af",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_labels = 'csv_labels'\n",
    "old_data   = 'old_data'\n",
    "new_data   = 'new_data'\n",
    "destination = 'AUGMENTATION\\\\augmented'\n",
    "\n",
    "columns = ['quicksort', 'mergesort', 'selectionsort', 'insertionsort', 'bubblesort', 'linearsearch', 'binarysearch', 'linkedlist', 'hashmap']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb55449-4ec0-4a48-909f-87775f374934",
   "metadata": {},
   "source": [
    "### CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8fb0a3fc-99fc-4719-8f4c-c98d83cb2890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hash-Map'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = lambda key : (filter(lambda fname: key in fname, os.listdir('csv_labels')));\n",
    "folder_name = lambda fname : fname[4:-4]\n",
    "folder_name('old-Hash-Map.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "69adcb2d-624e-4de7-8cfb-9d4281947fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_data\\Hash-Map\n",
      "old_data\\Linked-List\n",
      "old_data\\Search-Binary\n",
      "old_data\\Search-Linear\n",
      "old_data\\Sort-Bubble\n",
      "old_data\\Sort-Insertion\n",
      "old_data\\Sort-Merge\n",
      "old_data\\Sort-Quick\n",
      "old_data\\Sort-Selection\n",
      "old_data\\Sort-zOthers\n",
      "9843\n"
     ]
    }
   ],
   "source": [
    "new_csvs = csv_files('new')\n",
    "old_csvs = csv_files('old')\n",
    "\n",
    "file_counter = 0\n",
    "file_not_founds = 0\n",
    "indentation_errors = 0\n",
    "\n",
    "java = 0\n",
    "python = 0\n",
    "\n",
    "old_csv_data = []\n",
    "\n",
    "\n",
    "for csv_filename in old_csvs:\n",
    "    folder = f'{old_data}\\\\{folder_name(csv_filename)}'\n",
    "    df = pd.read_csv(f'{csv_labels}\\\\{csv_filename}')\n",
    "    \n",
    "    print(folder)\n",
    "    \n",
    "    for idx, row in df.iterrows():        \n",
    "        labels = row[columns].to_dict()\n",
    "        filename = row['Filename']\n",
    "        if sum(df[columns].iloc[idx]) == 0:\n",
    "            continue # If there are no labels here, do not augment it.\n",
    "        \n",
    "        labels['Filename'] = file_counter\n",
    "        \n",
    "        fname_splitted = filename.split('.')\n",
    "        \n",
    "        if (len(fname_splitted)) >= 2:\n",
    "            extension = fname_splitted[len(fname_splitted) - 1]\n",
    "            fname1 = fname_splitted[0:len(fname_splitted) - 1]\n",
    "        else:\n",
    "            fname1 = fname_splitted\n",
    "            extension = 'py'\n",
    "        \n",
    "        if extension == 'js':\n",
    "            # If javascript, continue. We do not augment it.\n",
    "            continue\n",
    "        \n",
    "        # Now, we get the file with the filename\n",
    "        try:\n",
    "            for _ in range(randint(0, 35)):\n",
    "                label1 = deepcopy(labels)\n",
    "                with open(f'{folder}\\\\{filename}', encoding='utf8', errors='ignore') as file:\n",
    "                    if extension == 'java':\n",
    "                        q = c_cleaner(file.read())\n",
    "                        q = generate_new_code(q, 'java')\n",
    "                        java += 1\n",
    "                    elif extension == 'py':\n",
    "                        print(\"test\")\n",
    "                        python += 1\n",
    "                        q = py_cleaner(file.read())\n",
    "                        q = generate_new_code(q, 'py')\n",
    "                        \n",
    "                    filename1 = f'augmented_{file_counter}.{extension}'\n",
    "                    # Copy the file\n",
    "                    with open(f'{destination}\\\\{filename1}', 'w', encoding='utf8') as newfile:\n",
    "                        newfile.write(q)\n",
    "                label1['Filename'] = filename1\n",
    "                old_csv_data.append(label1)\n",
    "                file_counter += 1\n",
    "        except FileNotFoundError:\n",
    "            file_not_founds += 1\n",
    "        except IndentationError:\n",
    "            indentation_errors += 1\n",
    "        except:\n",
    "            # WHATEVER\n",
    "            pass\n",
    "        #print(old_csv_data)\n",
    "print(len(old_csv_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aee0b9da-46fc-4beb-bb7d-be1b9926696d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1114\n"
     ]
    }
   ],
   "source": [
    "new_csv_data = []\n",
    "\n",
    "for csv_filename in new_csvs:\n",
    "    folder = f'{new_data}/{folder_name(csv_filename)}'\n",
    "    \n",
    "    df = pd.read_csv(f'{csv_labels}/{csv_filename}')\n",
    "    \n",
    "    for idx, row in df.iterrows():        \n",
    "        labels = row[columns].to_dict()\n",
    "        filename = row['Filename']\n",
    "        \n",
    "        if sum(df[columns].iloc[idx]) == 0:\n",
    "            continue # If there are no labels here, do not augment it.\n",
    "        \n",
    "        labels['Filename'] = file_counter\n",
    "        \n",
    "        fname_splitted = filename.split('.')\n",
    "        \n",
    "        if (len(fname_splitted)) >= 2:\n",
    "            extension = fname_splitted[len(fname_splitted) - 1]\n",
    "            fname1 = fname_splitted[0:len(fname_splitted) - 1]\n",
    "        else:\n",
    "            fname1 = fname_splitted\n",
    "            extension = 'py'\n",
    "        \n",
    "        if extension == 'js':\n",
    "            # If javascript, continue. We do not augment it.\n",
    "            continue\n",
    "        \n",
    "        # Now, we get the file with the filename\n",
    "        try:\n",
    "            for _ in range(randint(0, 40)):\n",
    "                label1 = deepcopy(labels)\n",
    "                with open(f'{folder}/{filename}', encoding='utf8', errors='ignore') as file:\n",
    "                    if extension == 'java':\n",
    "                        q = c_cleaner(file.read())\n",
    "                        q = generate_new_code(q, 'java')\n",
    "                        java += 1\n",
    "                    elif extension == 'py':\n",
    "                        q = py_cleaner(file.read())\n",
    "                        q = generate_new_code(q, 'py')\n",
    "                        python += 1\n",
    "                    filename1 = f'augmented_{file_counter}.{extension}'\n",
    "                    # Copy the file\n",
    "                    with open(f'{destination}/{filename1}', 'w', encoding='utf8') as newfile:\n",
    "                        newfile.write(q)\n",
    "                file_counter += 1\n",
    "                label1['Filename'] = filename1\n",
    "                new_csv_data.append(label1)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            file_not_founds += 1\n",
    "        except IndentationError:\n",
    "            indentation_errors += 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print(len(new_csv_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3ceb49f8-5e66-45bb-992b-3fdda552b590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19263\n"
     ]
    }
   ],
   "source": [
    "intercalated_data = []\n",
    "\n",
    "df = pd.read_csv(f'Intercalated.csv')\n",
    "    \n",
    "for idx, row in df.iterrows():        \n",
    "    labels = row[columns].to_dict()\n",
    "    filename = row['Filename']\n",
    "\n",
    "    labels['Filename'] = file_counter\n",
    "        \n",
    "    fname_splitted = filename.split('.')\n",
    "        \n",
    "    if (len(fname_splitted)) >= 2:\n",
    "        extension = fname_splitted[len(fname_splitted) - 1]\n",
    "        fname1 = fname_splitted[0:len(fname_splitted) - 1]\n",
    "    else:\n",
    "        fname1 = fname_splitted\n",
    "        extension = 'py'\n",
    "        \n",
    "    if extension == 'js':\n",
    "        # If javascript, continue. We do not augment it.\n",
    "        continue\n",
    "        \n",
    "    # Now, we get the file with the filename\n",
    "    try:\n",
    "        for _ in range(randint(0, 6)):\n",
    "            label1 = deepcopy(labels)\n",
    "            with open(f'intercalate_augment/{filename}', encoding='utf8', errors='ignore') as file:\n",
    "                if extension == 'java':\n",
    "                    q = c_cleaner(file.read())\n",
    "                    q = generate_new_code(q, 'java')\n",
    "                    java += 1\n",
    "                elif extension == 'py':\n",
    "                    q = py_cleaner(file.read())\n",
    "                    q = generate_new_code(q, 'py')\n",
    "                    python += 1\n",
    "                filename1 = f'augmented_{file_counter}.{extension}'\n",
    "                # Copy the file\n",
    "                with open(f'{destination}/{filename1}', 'w', encoding='utf8') as newfile:\n",
    "                    newfile.write(q)\n",
    "            file_counter += 1\n",
    "            label1['Filename'] = filename1\n",
    "            intercalated_data.append(label1)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        file_not_founds += 1\n",
    "    except IndentationError:\n",
    "        indentation_errors += 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(len(intercalated_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "90797b25-07c7-4b92-b006-684624f1b228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30220"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dictionaries = old_csv_data + new_csv_data + intercalated_data\n",
    "len(final_dictionaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9843"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dictionaries = old_csv_data\n",
    "len(final_dictionaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d47d105c-9a07-4f1a-980c-d2d74aecad5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2aa72bb01e05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlabel_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_dictionaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlabel_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "label_file = pd.DataFrame(final_dictionaries)\n",
    "label_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "11304abc-2a89-438d-b211-bf14cb0005d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total augmented Java files: 30220 | python files: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Total augmented Java files: {java} | python files: {python}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2f9c1c-2b11-4936-aa5a-68e4afcb0af6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7582e50fb2f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'label_file' is not defined"
     ]
    }
   ],
   "source": [
    "sum(label_file[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f40840bd-6478-4086-8aca-92e0e28ccf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file.to_csv('AUGMENTATION/augmented.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1240a082-5c65-468d-a995-69cb42985947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
